{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553f1ee5-bb78-414d-92f0-0683f74262a6",
   "metadata": {},
   "source": [
    "# Evaluación de calidad de carros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f295128-60e6-44d4-9c20-102117178eba",
   "metadata": {},
   "source": [
    "# Cindy Johanna Zapata Romero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f599c135-45f7-4bc6-8696-89e4b21a86cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Obtaining dependency information for ucimlrepo from https://files.pythonhosted.org/packages/22/47/9350b2eeeaef8c0fd3ec3505c8a0481b576845b3df0d71c76f989c23d3c6/ucimlrepo-0.0.6-py3-none-any.whl.metadata\n",
      "  Downloading ucimlrepo-0.0.6-py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cca8ccb-a611-400f-bab9-576065bdbfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 19, 'name': 'Car Evaluation', 'repository_url': 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'data_url': 'https://archive.ics.uci.edu/static/public/19/data.csv', 'abstract': 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', 'area': 'Other', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1728, 'num_features': 6, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1988, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5JP48', 'creators': ['Marko Bohanec'], 'intro_paper': {'title': 'Knowledge acquisition and explanation for multi-attribute decision making', 'authors': 'M. Bohanec, V. Rajkovič', 'published_in': '8th Intl Workshop on Expert Systems and their Applications, Avignon, France', 'year': 1988, 'url': 'https://www.semanticscholar.org/paper/KNOWLEDGE-ACQUISITION-AND-EXPLANATION-FOR-DECISION-Bohanec-Rajkovi%C4%8D/8bab443ae322ff47c3e609272bd93fd4650555bc', 'doi': None}, 'additional_info': {'summary': 'Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:\\r\\n\\r\\nCAR                      car acceptability\\r\\n. PRICE                  overall price\\r\\n. . buying               buying price\\r\\n. . maint                price of the maintenance\\r\\n. TECH                   technical characteristics\\r\\n. . COMFORT              comfort\\r\\n. . . doors              number of doors\\r\\n. . . persons            capacity in terms of persons to carry\\r\\n. . . lug_boot           the size of luggage boot\\r\\n. . safety               estimated safety of the car\\r\\n\\r\\nInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\\r\\n\\r\\nThe Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.\\r\\n\\r\\nBecause of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'buying:   vhigh, high, med, low.\\nmaint:    vhigh, high, med, low.\\ndoors:    2, 3, 4, 5more.\\npersons:  2, 4, more.\\nlug_boot: small, med, big.\\nsafety:   low, med, high.', 'citation': None}}\n",
      "       name     role         type demographic  \\\n",
      "0    buying  Feature  Categorical        None   \n",
      "1     maint  Feature  Categorical        None   \n",
      "2     doors  Feature  Categorical        None   \n",
      "3   persons  Feature  Categorical        None   \n",
      "4  lug_boot  Feature  Categorical        None   \n",
      "5    safety  Feature  Categorical        None   \n",
      "6     class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                       buying price  None             no  \n",
      "1                           price of the maintenance  None             no  \n",
      "2                                    number of doors  None             no  \n",
      "3              capacity in terms of persons to carry  None             no  \n",
      "4                           the size of luggage boot  None             no  \n",
      "5                        estimated safety of the car  None             no  \n",
      "6  evaulation level (unacceptable, acceptable, go...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "car_evaluation = fetch_ucirepo(id=19) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = car_evaluation.data.features \n",
    "y = car_evaluation.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(car_evaluation.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(car_evaluation.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c155d1-fac3-4d37-a57d-3146d94a77ba",
   "metadata": {},
   "source": [
    "# Descripción del Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c9787-9116-4ca7-be6f-e434f247e389",
   "metadata": {},
   "source": [
    "El conjunto de datos \"Car Evaluation\" está relacionado con un modelo de decisión jerárquico en el que se evalúa la aceptabilidad de un automóvil. Se desarrolló originalmente para demostrar el sistema DEX (Decision EXpert), e incluye seis atributos directamente relacionados con la aceptabilidad general de un automóvil.\n",
    "\n",
    "### Atributos\n",
    "\n",
    "1. **buying**: Representa el precio de compra (`vhigh`, `high`, `med`, `low`).\n",
    "2. **maint**: Costo de mantenimiento (`vhigh`, `high`, `med`, `low`).\n",
    "3. **doors**: Número de puertas (`2`, `3`, `4`, `5more`).\n",
    "4. **persons**: Número de personas que el automóvil puede llevar (`2`, `4`, `more`).\n",
    "5. **lug_boot**: Tamaño del maletero (`small`, `med`, `big`).\n",
    "6. **safety**: Nivel de seguridad estimado (`low`, `med`, `high`).\n",
    "\n",
    "### Variable objetivo\n",
    "\n",
    "- **class**: Evalúa la aceptabilidad del automóvil (`unacceptable`, `acceptable`, `good`, `very good`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4feb659-7343-42b1-929d-40c0815a0d24",
   "metadata": {},
   "source": [
    "# Exploración y preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d372258-7be0-4329-a305-24b2c5a1bc14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas de los datos:\n",
      "  buying  maint doors persons lug_boot safety  class\n",
      "0  vhigh  vhigh     2       2    small    low  unacc\n",
      "1  vhigh  vhigh     2       2    small    med  unacc\n",
      "2  vhigh  vhigh     2       2    small   high  unacc\n",
      "3  vhigh  vhigh     2       2      med    low  unacc\n",
      "4  vhigh  vhigh     2       2      med    med  unacc\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Obtenemos el conjunto de datos Car Evaluation usando ucimlrepo\n",
    "car_evaluation = fetch_ucirepo(id=19)\n",
    "\n",
    "X = car_evaluation.data.features\n",
    "y = car_evaluation.data.targets\n",
    "\n",
    "# Procedo a combinar ambos df en un solo para realizar una mejor exploración de los datos\n",
    "car_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Mostramos las primeras filas de los datos\n",
    "print(\"Primeras filas de los datos:\")\n",
    "print(car_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcc17764-b5dc-4c03-ab41-0c79d7613cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información general del DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   buying    1728 non-null   object\n",
      " 1   maint     1728 non-null   object\n",
      " 2   doors     1728 non-null   object\n",
      " 3   persons   1728 non-null   object\n",
      " 4   lug_boot  1728 non-null   object\n",
      " 5   safety    1728 non-null   object\n",
      " 6   class     1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostramos la información básica sobre las columnas y los tipos de datos\n",
    "print(\"\\nInformación general del DataFrame:\")\n",
    "print(car_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69836320-83db-4c6a-8959-b03c54311d77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen estadístico de las características categóricas:\n",
      "       buying  maint doors persons lug_boot safety  class\n",
      "count    1728   1728  1728    1728     1728   1728   1728\n",
      "unique      4      4     4       3        3      3      4\n",
      "top     vhigh  vhigh     2       2    small    low  unacc\n",
      "freq      432    432   432     576      576    576   1210\n"
     ]
    }
   ],
   "source": [
    "# Generamos un resumen estadístico de las características categóricas\n",
    "print(\"\\nResumen estadístico de las características categóricas:\")\n",
    "print(car_data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "074ac01e-4b68-4aef-8596-813e07242d02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¿Hay valores nulos en el conjunto de datos?\n",
      "buying      0\n",
      "maint       0\n",
      "doors       0\n",
      "persons     0\n",
      "lug_boot    0\n",
      "safety      0\n",
      "class       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Procedo a verificar los valores nulos\n",
    "print(\"\\n¿Hay valores nulos en el conjunto de datos?\")\n",
    "print(car_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93686c5-87a1-4af5-847e-32a8d1328626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de las clases objetivo:\n",
      "class\n",
      "unacc    1210\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verifico las distribuciones de las clases objetivo\n",
    "print(\"\\nDistribución de las clases objetivo:\")\n",
    "print(car_data['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e8ae50-ab82-497d-8b63-2fafe8b73264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilizo get_dummies para convertir a variables dummy (preparación para el modelado)\n",
    "car_data_encoded = pd.get_dummies(car_data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f05f7a14-0ad0-4c8e-84fe-6420b1b0ebfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datos codificados (variables dummy):\n",
      "   buying_low  buying_med  buying_vhigh  maint_low  maint_med  maint_vhigh  \\\n",
      "0       False       False          True      False      False         True   \n",
      "1       False       False          True      False      False         True   \n",
      "2       False       False          True      False      False         True   \n",
      "3       False       False          True      False      False         True   \n",
      "4       False       False          True      False      False         True   \n",
      "\n",
      "   doors_3  doors_4  doors_5more  persons_4  persons_more  lug_boot_med  \\\n",
      "0    False    False        False      False         False         False   \n",
      "1    False    False        False      False         False         False   \n",
      "2    False    False        False      False         False         False   \n",
      "3    False    False        False      False         False          True   \n",
      "4    False    False        False      False         False          True   \n",
      "\n",
      "   lug_boot_small  safety_low  safety_med  class_good  class_unacc  \\\n",
      "0            True        True       False       False         True   \n",
      "1            True       False        True       False         True   \n",
      "2            True       False       False       False         True   \n",
      "3           False        True       False       False         True   \n",
      "4           False       False        True       False         True   \n",
      "\n",
      "   class_vgood  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n"
     ]
    }
   ],
   "source": [
    "# Mostramos una muestra de los datos codificados\n",
    "print(\"\\nDatos codificados (variables dummy):\")\n",
    "print(car_data_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03aa30-3cc9-48f6-a870-d989f5ebc882",
   "metadata": {},
   "source": [
    "# Generación de conjuntos de entrenamiento y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1105b650-545a-4ac5-9ce4-40959ceb1603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importamos el módulo necesario para la separación de los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Obtenemos el conjunto de datos Car Evaluation usando ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "car_evaluation = fetch_ucirepo(id=19)\n",
    "\n",
    "# Separamos las características (X) y el objetivo (y) en DataFrames\n",
    "X = car_evaluation.data.features\n",
    "y = car_evaluation.data.targets\n",
    "\n",
    "# Dividimos el conjunto de datos en entrenamiento y testeo\n",
    "# Separamos el 80% para entrenamiento y el 20% para testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "107454c1-8557-4b8f-beea-c516144c3e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 1382 muestras\n",
      "Tamaño del conjunto de testeo: 346 muestras\n"
     ]
    }
   ],
   "source": [
    "# Procedmos a mostrar el tamaño de los conjuntos generados\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Tamaño del conjunto de testeo: {X_test.shape[0]} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60336063-0552-4ecd-8874-840650093b5c",
   "metadata": {},
   "source": [
    "# Informe de rendimiento de modelos tras la implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a72c173-1fe3-4781-bbf2-f12254377d08",
   "metadata": {},
   "source": [
    "Para evaluar el rendimiento de los modelos tras la implementación, elegí el módelo de Árbol de Desición, entrenarlo con el conjunto de entrenamiento, y evaluar su rendimiento en el conjunto de testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cea3de78-c791-49aa-97db-e4f694151f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importamos el modelo de Árbol de Decisión y las métricas para evaluación\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d07ea107-99b9-4696-83c3-8db9123db310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtenemos el conjunto de datos\n",
    "car_evaluation = fetch_ucirepo(id=19)\n",
    "\n",
    "# Separamos las características (X) y el objetivo (y) en DataFrames\n",
    "X = car_evaluation.data.features\n",
    "y = car_evaluation.data.targets['class']  # Procedo a Convertir el objetivo a Serie\n",
    "\n",
    "# Convertimos características categóricas a variables dummy\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Dividimos el conjunto de datos en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamos un modelo con el conjunto de entrenamiento\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos el conjunto de testeo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Generamos el informe de rendimiento\n",
    "report = classification_report(y_test, y_pred, target_names=y.unique())\n",
    "confusion = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "532a86e8-f10d-4efd-94ea-e3d3aa66d7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc       0.99      0.87      0.92        83\n",
      "         acc       0.62      0.91      0.74        11\n",
      "       vgood       0.98      1.00      0.99       235\n",
      "        good       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       346\n",
      "   macro avg       0.85      0.90      0.87       346\n",
      "weighted avg       0.96      0.96      0.96       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el informe de rendimiento\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43f1e588-f9df-405c-8fb5-50dda106e3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusión:\n",
      "[[ 72   4   5   2]\n",
      " [  0  10   0   1]\n",
      " [  0   0 235   0]\n",
      " [  1   2   0  14]]\n"
     ]
    }
   ],
   "source": [
    "# Mostramos la matriz de confusión\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba27e88-f8d9-4e2a-9f0f-7636513ea5f7",
   "metadata": {},
   "source": [
    "# Implementación y evaluación de varios modelos de aprendizaje utilizando Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80eb6da-c64f-404c-8319-ce0d20ea60aa",
   "metadata": {},
   "source": [
    "Para implementar y evaluar varios modelos de aprendizaje utilizando scikit-learn, elegí crear un pipeline que entrene y pruebe múltiples modelos, generando informes de clasificación para cada uno. para esto procedo con la importación de Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "380d7360-d7d9-460f-bfb4-cef91ea6cfaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importamos clasificadores de Scikit-Learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6edeb3c-0015-4ab1-8072-66947a984e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lista de clasificadores a probar\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Support Vector Machine': SVC(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Primero nos aseguramos de que las carácteristicas están formato NumPy\n",
    "X_train_np = X_train.values\n",
    "X_test_np = X_test.values\n",
    "\n",
    "# Usamos los datos convertidos a NumPy para el modelo KNN \n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train_np, y_train)\n",
    "\n",
    "# Predecimos el modelo KNN utilizando el conjunto de testeo convertido\n",
    "y_pred = knn_model.predict(X_test_np)\n",
    "\n",
    "# Generamos el informe de clasificación y la matriz de confusión\n",
    "report_knn = classification_report(y_test, y_pred, target_names=y.unique())\n",
    "confusion_knn = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f95698ca-8915-4d40-ab94-dcb66eabc8bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informe de clasificación para K-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc       0.78      0.75      0.77        83\n",
      "         acc       0.30      0.27      0.29        11\n",
      "       vgood       0.92      0.99      0.96       235\n",
      "        good       1.00      0.29      0.45        17\n",
      "\n",
      "    accuracy                           0.88       346\n",
      "   macro avg       0.75      0.58      0.62       346\n",
      "weighted avg       0.87      0.88      0.86       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInforme de clasificación para K-Nearest Neighbors:\")\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2f8ea5e-d361-4fbc-82f0-31d4f1daf779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusión para K-Nearest Neighbors:\n",
      "[[ 62   4  17   0]\n",
      " [  6   3   2   0]\n",
      " [  2   0 233   0]\n",
      " [  9   3   0   5]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMatriz de confusión para K-Nearest Neighbors:\")\n",
    "print(confusion_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e2d4b0-a303-4134-b508-cc6cd9bb8e60",
   "metadata": {},
   "source": [
    "# Análisis de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c565643-f61b-4030-91c9-8b638c4264ad",
   "metadata": {},
   "source": [
    "## Tamaño del Dataset\n",
    "- **Conjunto de entrenamiento:** 1382 muestras.\n",
    "- **Conjunto de testeo:** 346 muestras.\n",
    "\n",
    "## Modelos Implementados\n",
    "\n",
    "### Árbol de Decisión\n",
    "- **Precisión general en testeo:** 96%\n",
    "\n",
    "#### Detalles por Clase\n",
    "- **Precisión:**\n",
    "  - unacc: 99%\n",
    "  - acc: 62%\n",
    "  - good: 82%\n",
    "  - vgood: 98%\n",
    "- **Recall:**\n",
    "  - unacc: 87%\n",
    "  - acc: 91%\n",
    "  - good: 82%\n",
    "  - vgood: 100%\n",
    "- **F1-score:**\n",
    "  - unacc: 92%\n",
    "  - acc: 74%\n",
    "  - good: 82%\n",
    "  - vgood: 99%\n",
    "\n",
    "### K-Nearest Neighbors (KNN)\n",
    "- **Precisión general en testeo:** 88%\n",
    "\n",
    "#### Detalles por Clase\n",
    "- **Precisión:**\n",
    "  - unacc: 78%\n",
    "  - acc: 30%\n",
    "  - good: 100%\n",
    "  - vgood: 92%\n",
    "- **Recall:**\n",
    "  - unacc: 75%\n",
    "  - acc: 27%\n",
    "  - good: 29%\n",
    "  - vgood: 99%\n",
    "- **F1-score:**\n",
    "  - unacc: 77%\n",
    "  - acc: 29%\n",
    "  - good: 45%\n",
    "  - vgood: 96%\n",
    "\n",
    "## Conclusión\n",
    "El modelo de Árbol de Decisión demostró ser más efectivo en general, con mejores resultados en precisión, recall y F1-score para la mayoría de las clases en comparación con el modelo KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c808f52-5874-4efc-8c26-3b00fa875054",
   "metadata": {},
   "source": [
    "# Gracias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
